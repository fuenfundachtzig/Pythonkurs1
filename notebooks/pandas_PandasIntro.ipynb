{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Pandas\" data-toc-modified-id=\"Pandas-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pandas-data-formats\" data-toc-modified-id=\"Pandas-data-formats-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Pandas data formats</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pandas-Series:\" data-toc-modified-id=\"Pandas-Series:-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Pandas Series:</a></span></li><li><span><a href=\"#Pandas-Dataframe\" data-toc-modified-id=\"Pandas-Dataframe-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Pandas Dataframe</a></span><ul class=\"toc-item\"><li><span><a href=\"#select-data-regions-in-DataFrame:\" data-toc-modified-id=\"select-data-regions-in-DataFrame:-1.1.2.1\"><span class=\"toc-item-num\">1.1.2.1&nbsp;&nbsp;</span>select data regions in DataFrame:</a></span></li></ul></li><li><span><a href=\"#Change-content-of-dataframe\" data-toc-modified-id=\"Change-content-of-dataframe-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Change content of dataframe</a></span></li><li><span><a href=\"#Functions-can-be-applied-to-content\" data-toc-modified-id=\"Functions-can-be-applied-to-content-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Functions can be applied to content</a></span></li></ul></li><li><span><a href=\"#First-practical-example:-Old-faithful-data\" data-toc-modified-id=\"First-practical-example:-Old-faithful-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>First practical example: Old faithful data</a></span></li><li><span><a href=\"#Handling-missing-data-or-null-values-in-Pandas\" data-toc-modified-id=\"Handling-missing-data-or-null-values-in-Pandas-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Handling missing data or null-values in Pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Python-None-object\" data-toc-modified-id=\"Python-None-object-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Python None object</a></span></li><li><span><a href=\"#Python-NaN\" data-toc-modified-id=\"Python-NaN-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Python NaN</a></span></li><li><span><a href=\"#NaN-and-None-in-Pandas\" data-toc-modified-id=\"NaN-and-None-in-Pandas-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>NaN and None in Pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-with-real-data\" data-toc-modified-id=\"Example-with-real-data-1.3.3.1\"><span class=\"toc-item-num\">1.3.3.1&nbsp;&nbsp;</span>Example with real data</a></span></li></ul></li></ul></li><li><span><a href=\"#Aggregations-in-Panda\" data-toc-modified-id=\"Aggregations-in-Panda-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Aggregations in Panda</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grouping-in-Pandas\" data-toc-modified-id=\"Grouping-in-Pandas-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Grouping in Pandas</a></span></li></ul></li><li><span><a href=\"#Second-Example----Planets-Data\" data-toc-modified-id=\"Second-Example----Planets-Data-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Second Example -  Planets Data</a></span></li><li><span><a href=\"#Third-Example---Spread-sheet-data\" data-toc-modified-id=\"Third-Example---Spread-sheet-data-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Third Example - Spread sheet data</a></span></li><li><span><a href=\"#Fourth-Example---Time-series-data\" data-toc-modified-id=\"Fourth-Example---Time-series-data-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Fourth Example - Time series data</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "\n",
    "Pandas is a set of Python Modules for  data analysis, i.e. \n",
    "\n",
    "* IO Tools to handle many different data formats, such as   *txt, csv, xls, json, hdf5, sql, ...*\n",
    "* Tools to manipulate (filter, fix, extract, extend, ...) the data\n",
    "* special visualization tools (on top of matplotlib)\n",
    "* many features to combine, group, select, aggregate  specific properties of the data\n",
    "\n",
    "A couple of smart instructions in pandas allow complex data-mining procedures which would otherwise take substantial programming effort.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas data formats\n",
    "\n",
    "Pandas builds on special array types, which build/extend numpy arrays.\n",
    "\n",
    "* Series: one-dimensional array, can contain different data types, and supports flexible indexing\n",
    "* DataFrame: two-dimensional array, basically a table with rows and columns, can also contain different data types and has very \n",
    "flexible indexing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Setup: \n",
    "import pandas as pd\n",
    "# and usually as well:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=pd.Series([4,3,5,-6])\n",
    "print(type(obj))\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas series is not just array but has associated index\n",
    "print(obj.values)\n",
    "print(obj.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(obj.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default index is just integer range\n",
    "#\n",
    "# But can specify different index explizitly:\n",
    "\n",
    "obj=pd.Series([4,3,5,-6],index=['a','b','c','d'])\n",
    "print(obj)\n",
    "print(obj.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use explicit index 'a'-'d' for range\n",
    "obj['a':'c'] # watch out, last element included "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or implicit numerical index:\n",
    "obj[0:2] # watch out, last element not included "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or change index later on:\n",
    "obj.index=['I','II','III','IV']\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual numpy array operations can be used for Pandas series\n",
    "\n",
    "obj[obj>3] # select elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj**2 # square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(obj) # exp fct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Dataframe\n",
    "\n",
    "the 2D version, they have both row and column index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example creation \n",
    "# list of dates and row index\n",
    "dates = pd.date_range('20130101', periods=6).to_native_types()\n",
    "print(dates)\n",
    "# list of chars as row-index\n",
    "cols=list('ABCD')\n",
    "# real data as numpy 2d array filled with randoms nums:\n",
    "mydata = np.random.randn(6,4)\n",
    "df = pd.DataFrame( mydata, index=dates, columns=cols)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### select data regions in DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column\n",
    "df['A'] # column index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.A # in most cases also this notation works to select col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select row with loc and explicit index\n",
    "print(df.loc['2013-01-05'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select row with iloc and implicit index\n",
    "print(df.iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element with col and row\n",
    "df['B'].loc['2013-01-05']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or more direct\n",
    "df['B']['2013-01-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or range of rows\n",
    "df['A']['2013-01-01':'2013-01-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or implicit row index\n",
    "df['B'][0:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A']['2013-01-01':'2013-01-05']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Selecting range of rows also needs function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['B':'C',:] # naive attempt does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'B':'C'] # df.loc allows to select arbitrary regions with key index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,1:3] # equivalent with numerical col index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:4,2:4] # arbitrary sub-range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose row <--> columns\n",
    "df.T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change content of dataframe\n",
    "Many nice ways to modify content, some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy() # independent copy\n",
    "#df3['2013-01-04']\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete row\n",
    "df4=df3.drop('2013-01-04')\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 unchanged\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete column, need to specify axis\n",
    "# and set inplace to make change in Dataframe\n",
    "df3.drop('A',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column\n",
    "df4 = df.copy()\n",
    "df4['E'] = ['one', 'one','two','three','four','three']\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select specific rows \n",
    "df4[df4['E'].isin(['two','four'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions can be applied to content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.cumsum) # cumulative sum in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.exp) # exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".... and much more stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First practical example: Old faithful data \n",
    "*(Eruptions of Geysir in Yellowstone National Park)*\n",
    "\n",
    "Redo it with Pandas ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse old faithful data with pandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# can read data directly from web\n",
    "# interpret as csv format \n",
    "# and import as Pandas dataframe \n",
    "d=pd.read_csv('https://people.sc.fsu.edu/~jburkardt/data/csv/faithful.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.info() # extract general info on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head() # inspect first lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.describe() # some basic statistic for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lengthy column names are unpractical, re-name\n",
    "d.columns=['Index','El','Ew']\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (d.Ew) # print all rows for Ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots directly with Pandas\n",
    "d.El.plot.hist() # can call directly histogram for Pandas column\n",
    "plt.xlabel('El')\n",
    "fig=plt.figure() # trick to make new hist plot\n",
    "d.Ew.plot.hist()\n",
    "plt.xlabel('Ew')\n",
    "d.plot.scatter('Ew','El'); # and also scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing data or null-values in Pandas\n",
    "\n",
    "#### Python None object\n",
    "Python has special object `None` which is often used to specify empty or unassigned value to a variable\n",
    "\n",
    "This can also be used or happen with Numpy/Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "vals1 = np.array([1, None, 3, 4])\n",
    "vals1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results in object-array with very limited use,\n",
    "# many numpy funcs/operations broken\n",
    "vals1**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python NaN\n",
    "NaN (Not-a-number) is special floating point value which indicates that value cannot be treated as regular number, generally used in programming as specified in IEEE floating-point standard.\n",
    "\n",
    "Also defined for numpy (`np.nan`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals2 = np.array([1, np.nan, 3, 4]) \n",
    "vals2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results in float array which can be used\n",
    "# just no operation with the nan element  \n",
    "vals2**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  NaN and None in Pandas\n",
    "\n",
    "Pandas does not make that strict distinction but treats ``NaN`` and ``None`` basically the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas converts to nan and float array\n",
    "a=pd.Series([1, np.nan, 2, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has special functions to efficienlty handle None/NaN valuse:\n",
    "\n",
    "- ``isnull()``: Generate a boolean mask indicating missing values\n",
    "- ``notnull()``: Opposite of ``isnull()``\n",
    "- ``dropna()``: Return a filtered version of the data\n",
    "- ``fillna()``: Return a copy of the data with missing values filled or imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([1, np.nan, 'hello', None])\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (data.isnull()) # boolean output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (data[data.notnull()]) # select only non-missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (data.dropna()) # does the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (data.fillna('Fehlt leider')) # fill something instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For  **Dataframes** there are many more options for dropping (both axes) and filling, see chapter *Handling Missing Data* in Book "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example with real data\n",
    "'planets' data (discussed further below) has many missing entries\n",
    "\n",
    "Needs seaborn package:\n",
    "\n",
    "Use alternative python setup: \n",
    "\n",
    "`module load anaconda3/2019.07 ` in shell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "planets = sns.load_dataset('planets')\n",
    "planets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.mass.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Aggregations in Panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple df with gaussian random nums\n",
    "df = pd.DataFrame({'A': np.random.randn(5),\n",
    "                   'B': np.random.randn(5), 'C': np.random.randn(5)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # gives column-wise statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These **aggregations** can also be called explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df.A.mean(), df.A.std(), df.B.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default aggregation is column-wise but one can also do row-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis='columns') # gives mean value by row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table summarizes some other built-in Pandas aggregations:\n",
    "\n",
    "| Aggregation              | Description                     |\n",
    "|--------------------------|---------------------------------|\n",
    "| ``count()``              | Total number of items           |\n",
    "| ``first()``, ``last()``  | First and last item             |\n",
    "| ``mean()``, ``median()`` | Mean and median                 |\n",
    "| ``min()``, ``max()``     | Minimum and maximum             |\n",
    "| ``std()``, ``var()``     | Standard deviation and variance |\n",
    "| ``mad()``                | Mean absolute deviation         |\n",
    "| ``prod()``               | Product of all items            |\n",
    "| ``sum()``                | Sum of all items                |\n",
    "\n",
    "These are all methods of ``DataFrame`` and ``Series`` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping in Pandas\n",
    "A frequent use case is that one is not just interested in overall aggregation but separated or split according to other criteria or keys.\n",
    "\n",
    "A simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data': np.random.randn(6)}, columns=['key', 'data'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now one might be interested not just in overall aggregation (e.g. mean) but in aggregation separate for each key. \n",
    "Can in principle be done by selecting specific rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df[df.key=='A'])\n",
    "df[df.key=='A'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much more powerful alternative is to apply `groupby`, this automatically splits dataframe in subframes and then arbitrary aggregations can be applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `groupby` results in special object which allows subsequent aggregation calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Illustrative figure to show effect of groupby**\n",
    "* Sequence of\n",
    "  * Split\n",
    "  * Apply\n",
    "  * Combine\n",
    "\n",
    "![](figures/03.08-split-apply-combine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Example -  Planets Data\n",
    "\n",
    "Planets data comes with the  [Seaborn package](http://seaborn.pydata.org/).\n",
    "It gives information on planets that astronomers have discovered around other stars (known as *extrasolar planets* or *exoplanets* for short). It can be downloaded with a simple Seaborn command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "planets = sns.load_dataset('planets')\n",
    "planets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No big magic behind, simple csv file read via Pandas from Web server and stored as Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do usual inspection\n",
    "planets.info()\n",
    "planets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some missing data, might consider to remove these lines\n",
    "planets.dropna().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby('method').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or only specific columns\n",
    "planets.groupby('method')['orbital_period'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again describe can be applied on sub-split\n",
    "planets.groupby('method')['year'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Of course we can also plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.plot.scatter('mass','orbital_period')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gives useful information on dataset, e.g. Radial Velocity is most frequent method, followed by Transit, but latter only applied from 2013 onwards, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Example - Spread sheet data\n",
    "** WLCG Computing Resources ** see \n",
    "https://wlcg-rebus.cern.ch/apps/pledges/resources/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json input\n",
    "#dwlcg = pd.read_json('https://wlcg-rebus.cern.ch/apps/pledges/resources/2016/all/json')\n",
    "dwlcg = pd.read_json('http://www-static.etp.physik.uni-muenchen.de/kurs/Computing/sw/source/wlcg.json')\n",
    "dwlcg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwlcg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwlcg.describe() # not very meaningful, data too inhomogenous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwlcg.ATLAS.mean() # select col ATLAS and try to get mean -> error\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gives error:  \n",
    "Empty fields had been filled as empty string (\"\"), therefore columns which should contain numeric data have mix of numeric and string data and are treated as un-specific   *object* data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwlcg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix by enforcing conversion into numeric field\n",
    "for s in ['ATLAS','CMS','ALICE','LHCb']:\n",
    "    dwlcg[s]=dwlcg[s].apply(pd.to_numeric)\n",
    "    print (s, dwlcg[s].count(), dwlcg[s].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwlcg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwlcg.ATLAS.mean() # now mean works ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not meaningfull, mix of different types of resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwlcg.groupby(['PledgeType'])['ATLAS'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum of resources for ATLAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwlcg.groupby(['PledgeType']).mean() # for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further breakdown by country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwlcg.groupby(['PledgeType','Country'])['ATLAS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also be further  used:\n",
    "r = dwlcg.groupby(['PledgeType','Country'])['ATLAS'].sum()\n",
    "print (r['CPU'])\n",
    "print ('CPU UK:', r['CPU','UK'])\n",
    "r[:,'UK']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr=r.unstack() # back to regular dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Remark:**  \n",
    "Such a spreadsheet can also be regarded as multi-dimensional data format:\n",
    "1. Country\n",
    "1. Federation\n",
    "1. Experiment\n",
    "1. PledgeType\n",
    "\n",
    "For practical reasons it is stored and filled as a 2D table.\n",
    "But with groupby one can basically get back these extra dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Example - Time series data\n",
    "Example on weather/climate data:\n",
    "\n",
    "The \"Deutsche Wetterdienst\" has an archive with many decades of daily measurements from many weatherstations all over Germany:  http://www.dwd.de/DE/leistungen/klimadatendeutschland/klarchivtagmonat.html,\n",
    "One Example is the dataset from Zugspitze Station which dates back to \n",
    "August 1, 1900.\n",
    "\n",
    "The analysis of that data is instructive, e.g. to look for effects of climate change.\n",
    "\n",
    "Pandas provides a few special methods which are very useful for time-series analysis:\n",
    "- easy selection of time-periods\n",
    "- resampling/averaging of data over arbitrary intervals\n",
    "  - days, weeks, months, years..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "# csv data file from zip file dowlnoad from \n",
    "# http://www.dwd.de/DE/leistungen/klimadatendeutschland/klarchivtagmonat.html\n",
    "# Messdatum als index und Interpretation als Datum (nicht nur String) \n",
    "#df=pd.read_csv('http://www-static.etp.physik.uni-muenchen.de/kurs/Computing/sw/source/produkt_klima_Tageswerte_19000801_20151231_05792.txt',';\\s*',index_col='MESS_DATUM',parse_dates=['MESS_DATUM'],skipfooter=1)\n",
    "\n",
    "df=pd.read_csv('http://www-static.etp.physik.uni-muenchen.de/kurs/Computing/sw/source/produkt_klima_tag_19000801_20181231_05792.txt',';\\s*',index_col='MESS_DATUM',parse_dates=['MESS_DATUM'],engine='python')\n",
    "print (df.size)\n",
    "print (df.columns)\n",
    "df.info()\n",
    "\n",
    "# kryptische Abkuerzungen...\n",
    "# TMK = mittlere Temperatur\n",
    "# SHK_TAG = Schneehoehe\n",
    "# ..\n",
    "# Details siehe http://www-static.etp.physik.uni-muenchen.de/kurs/Computing/sw/source/Metadaten_Parameter_klima_tag_05792.html\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TMK']\n",
    "\n",
    "df['TMK'].plot();\n",
    "# starke Schwankungen, kein Trend erkennbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur fuer 1 Jahr\n",
    "df['TMK']['1901'].plot();\n",
    "# crucial to have Index recognized as date \n",
    "# to allow selection of time period ('1901'), etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seit 2005\n",
    "df['TMK']['2005':].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-sample over year\n",
    "dfy=df['TMK'].resample('A').mean()\n",
    "dfy.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg per quarter\n",
    "dfq=df['TMK'].resample('Q-NOV').mean()\n",
    "\n",
    "# Winter\n",
    "dfq[dfq.index.quarter==1].plot()\n",
    "\n",
    "# Summer\n",
    "plt.figure()\n",
    "dfq[dfq.index.quarter==3].plot()\n",
    "\n",
    "# since 1970\n",
    "plt.figure()\n",
    "dfq[(dfq.index.quarter==3) & (dfq.index.year>1970)].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
